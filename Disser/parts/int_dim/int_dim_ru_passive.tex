\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
% Russian language support
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\bibliographystyle{IEEEtran}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Анализ внутренней размерности популяционной активности нейронов\\

\thanks{Данная работа выполнена при поддержке Некоммерческого фонда поддержки науки и образования «ИНТЕЛЛЕКТ». Н.П. выражает благодарность за поддержку программе Brain Научно-исследовательского центра IDEAS.}
}

\author{\IEEEauthorblockN{Никита Поспелов}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\ \textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
pospelov.na14@physics.msu.ru}
\and
\IEEEauthorblockN{Ольга Рогожникова}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\
\textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
osrogozhnikova@gmail.com}
\and
\IEEEauthorblockN{Виктор Плюснин}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\
\textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
witkax@mail.ru}
\and

\IEEEauthorblockN{Ксения Торопова}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\
\textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
xen.alexander@gmail.com}
\and

\IEEEauthorblockN{Ольга Ивашкина}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\
\textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
oivashkina@gmail.com}
\and

\IEEEauthorblockN{Владик Аветисов}
\IEEEauthorblockA{\textit{Институт химической физики им. Семёнова} \\
\textit{Российской академии наук}\\
Москва, Россия \\
vladik.avetisov@gmail.com}

\and
\IEEEauthorblockN{Константин Анохин}
\IEEEauthorblockA{\textit{Лаборатория нейронального интеллекта} \\
\textit{Институт перспективных исследований мозга} \\
\textit{Московский государственный университет}\\
Москва, Россия \\
k.anokhin@gmail.com}
}
\maketitle


\begin{abstract}
Применительно к нейронным данным гипотеза многообразия утверждает, что паттерны мозговой активности ограничены низкоразмерным многообразием, которое охватывает небольшую долю теоретически доступного пространства состояний. В данной работе эта гипотеза проверялась с использованием данных \textit{in vivo} кальциевого имиджинга нейронов гиппокампа мышей во время исследования новой арены. Была вычислена внутренняя размерность нейронной активности и проведено её сравнение с другими оценками размерности. Из-за неизбежной ограниченности \textit{in vivo} записей как по количеству регистрируемых нейронов, так и по длительности, были прослежены паттерны размерности по мере увеличения объёма доступных данных. Было обнаружено нетривиальное степенное масштабирование внутренней размерности в зависимости от количества регистрируемых нейронов и рассмотрена его потенциальная биологическая значимость.
\end{abstract}

\begin{IEEEkeywords}
Кальциевый имиджинг, гиппокамп, популяционная активность, внутренняя размерность, снижение размерности, степенной закон
\end{IEEEkeywords}

\section{Введение}
Плодотворной областью недавних исследований является применение методов обучения на многообразиях к нейронной активности. Этот подход использует тот факт, что нейронные данные, несмотря на их высокую размерность, часто следуют траектории гораздо более низкой размерности. Топологические структуры, образованные этими низкоразмерными нейронными подпространствами, известны как \textit{нейронные многообразия} \cite{Gallego2017} и могут предложить ценное понимание взаимосвязи между динамикой нейронных цепей, когнитивными процессами и поведенческой производительностью.

Снижение размерности оказалось ценным методом для получения представлений о коллективной нейронной активности путём дешифровки огромной сложности нейронной сигнализации в небольшое число соответствующих признаков, извлечённых из мультинейронных записей \cite{Cunningham2014}. Однако многообразия нейронной активности по своей природе нелинейны \cite{De2023}, и их низкая размерность часто скрывается методами анализа, которые предполагают линейность данных.

\textit{Внутренняя размерность} (ВР) — это количество коллективных мод (осей в некотором нелинейном пространстве), которое отражает природу информации, закодированной в коллективной активности. Это отличает её от различных мер «размерности вложения» — приблизительного числа измерений, исследуемых нейронным многообразием в евклидовом пространстве \cite{Jazayeri2021}.

В данной работе изучается внутренняя размерность данных кальциевого имиджинга из гиппокампальных записей мышей во время исследования новой арены. Проводится сравнение с размерностями, предполагающими линейность, а также изучаются законы масштабирования ВР с количеством нейронов.

\section{Методы}

\subsection{Кальциевый имиджинг}

Эксперименты проводились на самцах и самках мышей C57Bl/6 в возрасте 3-5 месяцев. Активность нейронов CA1 регистрировалась с помощью миниатюрного микроскопа (UCLA Miniscope V4.4, OpenEphys). Для этого животным проводилась стереотаксическая операция, в ходе которой в гиппокампальную область CA1 вводились вирусные частицы, несущие ген флуоресцентного кальциевого сенсора GCaMP6s, имплантировалась GRIN-линза (1 мм) и устанавливалось крепление для миниатюрного микроскопа. Мыши помещались для исследования новой арены на 10 минут в день в течение 4 последовательных дней. В арене были размещены четыре различных объекта, а на стенах — визуальные метки. Поведение животных записывалось с помощью видеокамеры (Flir Chameleon 3), синхронизация двух потоков данных осуществлялась в программной среде Bonsai \cite{lopes2015bonsai}. Всего в эксперименте использовалось 16 мышей, что дало в общей сложности 16*4=64 экспериментальных сессии.
Все методы ухода за животными и все экспериментальные протоколы были одобрены Комитетом по уходу за животными МГУ имени М.В. Ломоносова (заявка № 159-а, утверждённая на заседании Комиссии по биоэтике № 154-д от 17.08.2023) и полностью соответствовали Постановлению № 267 МЗ РФ, а также Руководству Национальных институтов здравоохранения США по уходу и использованию лабораторных животных.

\subsection{Предварительная обработка нейронной активности}

Анализ кальциевой активности проводился с использованием разработанного авторами программного пакета BEARMIND (https://github.com/iabs-neuro/bearmind) на основе пакета Caiman \cite{Pnevmatikakis2016}. Был выполнен первичный визуальный анализ захваченных видеозаписей и определены параметры пространственной обрезки, затем проводилась потоковая предварительная обработка видеоданных. Использовалась система коррекции движения на основе алгоритма NoRMCorre \cite{Pnevmatikakis2017}. Все выбранные компоненты прошли экспертную проверку для выявления артефактов и паразитных коррелированных компонент. Далее все компоненты (и их временные и пространственные декомпозиции), которые были отобраны и проверены, считались соответствующими нейронным сигналам. Полученные временные ряды кальциевой флуоресценции были нормализованы в форме $dF/F$, а пространственные компоненты были объединены между сессиями с использованием процедуры CellReg \cite{Sheintuch2017}.

\subsection{Оценка размерности}

Для анализа размерности данные временных рядов кальциевой флуоресценции рассматривались как набор из $T$ $N$-мерных точек, где $T$ — длина записи в кадрах, $N$ — количество нейронов. Для уменьшения шума временные ряды флуоресценции были свёрнуты с гауссовым ядром ($\sigma=2$). Для ускорения вычислений и уменьшения влияния автокорреляции использовался коэффициент прореживания 5.

Для сравнения использовались перемешанные сигналы от тех же нейронов. Для этого каждый сигнал циклически сдвигался на случайное число временных кадров $\Delta$, $\Delta_{min} < \Delta < T$, где $\Delta_{min} = 5$ с (типичное время автокорреляции сигнала кальциевой флуоресценции составляет $\sim 1-2$ с). Эта процедура перемешивания, сохраняя структуру сигналов, разрушает временные связи между ними. Следовательно, корреляции между активностью отдельных клеток и любые эффекты синхронизации, наблюдаемые на популяционном уровне, устраняются.

\textit{Линейная размерность} 

Оценка линейной размерности (ЛР) была получена путём применения анализа главных компонент (PCA) к данным активности. Данные, состоящие из $T$ точек в $N$-мерном пространстве, были преобразованы в главные компоненты, упорядоченные по объяснённой дисперсии в порядке убывания. ЛР оценивалась как наименьшее число компонент, чья кумулятивная объяснённая дисперсия превышала порог в 95\%. Этот подход идентифицировал целое число измерений, которое охватывало большую часть изменчивости данных.

\begin{figure}[ht]
\centering
\includegraphics[width=9cm]{int_dim/figs/growth.jpg}
\caption{Рост размерности с увеличением числа нейронов $N$ (слева) и временных кадров $T$ (справа). Голубой = основанная на PCA (линейная), зелёный = эффективная, красный = внутренняя размерность соответственно. Пунктирные линии соответствуют тем же размерностям, вычисленным на перемешанных данных. Затенённые области указывают ошибки SEM.}
\label{growth}
\end{figure}

\textit{Эффективная размерность} 

Эффективная размерность (ЭР) — это количество независимых переменных, которые создавали бы такой же паттерн ковариации, как данные многомерные данные, и поэтому достаточны для их описания \cite{edim}. Неравенство $ЭР \leq ЛР$ всегда выполняется, поскольку ЭР дополнительно учитывает «масштаб» распределения данных вдоль осей линейного подпространства. Её можно неформально описать как «взвешенную» линейную размерность, с весами, соответствующими важности конкретной оси для реконструкции дисперсии.
Для вычисления ЭР была вычислена «квадратичная энтропия» собственных значений корреляционной матрицы нейронов:

\begin{equation}
D_{eff} = \frac{(\sum_i \lambda_i)^2}{\sum_i \lambda_i^2}
\label{ed}
\end{equation}

где $\lambda_i \geq 0$ — собственные значения корреляционной матрицы $N \times N$ $C_{corr}$ (алгоритм подробно описан в \cite{effdim}).

\textit{Внутренняя размерность} 

Для вычисления оценок ВР был применён недавно предложенный оценщик 2-NN \cite{2nn}, который эффективно использует информацию о локальной окрестности для вычисления ВР. Этот алгоритм требует построения графа локальной окрестности только с двумя последовательными соседями, отсюда и название. Метод основан на том факте, что отношение расстояний между $i$-й точкой данных, её ближайшим соседом (БС) и следующим ближайшим соседом (СБС) распределено по закону Парето:

\begin{equation}
\mu_{i} = \frac{r_i^{СБС}}{r_i^{БС}} \sim \text{Парето}(1, d) \quad \mu_i \in (1, +\infty).
\end{equation}

где $d$ — внутренняя размерность подлежащего многообразия. Это позволяет извлечь оценку $d$ из эмпирической функции распределения $F_{emp}(\mu)$, полученной из набора отношений ${\mu_i}$ для всех точек данных, которая следует степенному закону с критическим показателем $d$.

На практике было обнаружено, что вместо численной подгонки кривой простая и надёжная оценка максимального правдоподобия, предложенная в \cite{gride}, даёт хорошие результаты:
\begin{equation}
ВР = \frac{n - 1}{\sum_{i=1}^{n} \log(\mu_{i})}
\label{id}
\end{equation}

\section{Результаты}


\begin{figure}[ht]
\centering
\includegraphics[width=9cm]{int_dim/figs/scaling.png}
\caption{Рост внутренней размерности (ВР) с увеличением числа нейронов $N$ для нейронной активности одного животного в течение 4 дней исследования арены. Красный = эмпирические данные, синий = перемешанные данные. Пурпурные линии представляют линейные подгонки, их значения $R^2$ и наклоны $\alpha$ приведены в легенде. Серая линия показывает начало области степенного масштабирования.}
\label{scaling}
\end{figure}

\subsection{Нейронная активность стабильно ограничена искривлённым многообразием низкой размерности}

Для сравнения поведения ВР с линейными мерами (ЛР и ЭР) были вычислены эти три меры при изменении как продолжительности сигнала $T$, так и количества нейронов в наборе данных $N$ для реальной и перемешанной активности (см. рис. \ref{growth}). Для масштабирования $N$ результаты усреднялись по различным упорядочениям нейронов, чтобы исключить эффекты предвзятой сортировки.

Линейные меры значительно увеличивались с временем записи, что предполагает, что встраивание нейронной активности в «высокоразмерный ящик» требует добавления новых измерений. В отличие от этого, ВР оставалась почти постоянной с ростом длины записи, что указывает на то, что многомерный сигнал с самого начала охватывал то же самое нелинейное пространство.

В соответствии с работой \cite{Jazayeri2021} обнаружено, что $ВР << ЭР$, что убедительно свидетельствует о том, что нейронная активность ограничена сильно искривлённым многообразием, которое не улавливается линейными методами. Неудивительно, что оценки размерности для перемешанных данных всегда были выше, чем для реальных данных, поскольку паттерны совместной активности и корреляционная структура, обеспечивающие основу низкой размерности, были нарушены. Разница между перемешанной и реальной активностью была наибольшей для ВР, поскольку она опирается на внутреннюю локальную структуру данных.


\subsection{Внутренняя размерность демонстрирует нетривиальное масштабирование с числом нейронов}

Все три меры размерности росли с увеличением числа нейронов $N$ (рис. \ref{growth}, слева). Для количественной оценки этого роста для ВР анализировался закон масштабирования для реальных и перемешанных данных (рис. \ref{scaling}). Была получена сильная подгонка по степенному закону с критическими показателями, лежащими в приблизительном диапазоне $0.1 \leq \alpha \leq 0.2$, что предполагает медленный рост размерности с увеличением $N$ ($d \sim N^{\alpha}$). Эти показатели были довольно стабильными между сессиями и, по-видимому, связаны с животным.

Чтобы выяснить, является ли это масштабирование простым следствием структуры многомерного временного ряда, анализ был повторён для перемешанных данных. Размерность перемешанных данных $ВР_{перемеш}$ демонстрировала ту же закономерность, но, но со значительно большими критическими показателями.

Было показано, что во все дни наклоны масштабирования $\alpha$ для реальных данных были значительно ниже, чем для перемешанных данных (рис. \ref{slopes}).
Для статистического анализа использовался однофакторный дисперсионный анализ (ANOVA), показавшего значительные различия наклонов масштабирования $\alpha$ в зависимости от типа данных (реальные или перемешанные).


\begin{figure}[ht]
\centering
\includegraphics[width=9cm]{int_dim/figs/slopes.jpg}
\caption{Распределения наклонов масштабирования ВР для реальной (зелёный) и перемешанной (синий) нейронной активности по дням. $**** p<0.00001$ для сравнения с перемешанной активностью}
\label{slopes}
\end{figure}

\section{Обсуждение}
Полученные результаты согласуются с текущими теоретическими представлениями взаимодействия ВР и ЭР \cite{Jazayeri2021}. Было показано, что размерность, основанная на разложении собственных значений корреляционной матрицы (аналогичная ЭР, используемой в данной работе), растёт линейно с размером ансамбля \cite{Mazzucato2016}.


Для широкого класса теоретических моделей было показано, что зависимость между внутренней и линейной размерностью является экспоненциальной \cite{De2023}. Результаты данной работы подчёркивают эту разницу: в то время как оценки размерности, предполагающие линейность, имеют порядок числа нейронов $N$, внутренняя размерность остаётся низкой, что означает, что нейронная активность ограничена сильно искривлённым многообразием.

Неограниченное степенное масштабирование размерности недавно было продемонстрировано при объёмной визуализации динамики нейронных популяций по всей коре (до 1 миллиона нейронов) \cite{Manley2024}. Однако авторы использовали линейную меру размерности, в то время как в данной работе вычисляется прямая оценка ВР. Насколько известно, степенное масштабирование ВР нейронной активности никогда ранее не демонстрировалось. Предполагается, что дальнейшие исследования возникающих критических показателей установят связь между этими «глобальными» свойствами динамики мозга и индивидуальной нейронной селективностью/избыточностью между нейронами. Результаты предполагают, что вместо того, чтобы говорить о «размерности данных $d$», следует сосредоточить внимание на законах масштабирования $d(N)$, поскольку они определяют, как размерность изменяется с размером системы (по крайней мере, пока размер записанной выборки мал $N << N_{мозг}$). Несмотря на обнаруженное неограниченное масштабирование ВР, результаты не противоречат гипотезе многообразия — $ВР(N)$ растёт медленно (напомним, что наклоны степенного закона $\alpha << 1$), и весьма вероятно, что степенной рост будет насыщен при больших $N$. Эти эффекты насыщения были показаны для масштабирования эффективной размерности в крупномасштабных записях в мозге рыбы-зебры \cite{Wang2025}, наряду со строгой вычислительной моделью, объясняющей кажущееся неограниченным степенное масштабирование.

В целом, нейронная активность не обязательно ограничена многообразием с фиксированной размерностью — ВР может изменяться со временем и демонстрировать различные свойства в разных масштабах. Рассмотрим гимнастическую ленту: с далёкой перспективы она кажется одномерной линией; в среднем масштабе это двумерный лист, причём одно измерение значительно больше другого; и при внимательном рассмотрении она имеет ненулевую толщину, что делает её трёхмерным объектом. Чтобы понять поведение размерности в разных масштабах, метод 2-NN, используемый в данной работе, может быть расширен для включения удалённых окрестностей \cite{gride}. Однако ограниченная продолжительность записей кальциевого имиджинга усложняет этот анализ, а также выявление потенциальных корреляций между ВР и поведением животного, оба из которых являются многообещающими областями для дальнейших исследований.

\section{Заключение}

В данной работе исследовано поведение внутренней размерности нейронной активности и проведено сравнение с мерами размерности, основанными на линейности. Подтверждено, что активность гиппокампальных популяций лежит на сильно искривлённом низкоразмерном многообразии, размерность которого остаётся почти постоянной во времени, в отличие от линейных мер. При исследовании масштабирования $ВР(N)$ с размером системы обнаружен степенной закон с малым критическим показателем $\alpha$, который не объясняется структурой временного ряда данных. Это масштабирование является характеристикой коллективной нейронной активности, и его количественная оценка может обеспечить дальнейшее понимание режимов нейронной активности на популяционном уровне.


\section{Благодарности}

Авторы благодарны С.К. Нечаеву и А.С. Горскому за плодотворные обсуждения.

\bibliography{references.bib}

\end{document}